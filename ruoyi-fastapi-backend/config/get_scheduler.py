import asyncio
import importlib
import json
import uuid
from asyncio import iscoroutinefunction
from collections.abc import Callable
from datetime import datetime, timedelta
from typing import Any

from apscheduler.events import EVENT_ALL, SchedulerEvent
from apscheduler.executors.asyncio import AsyncIOExecutor
from apscheduler.executors.pool import ProcessPoolExecutor
from apscheduler.job import Job
from apscheduler.jobstores.memory import MemoryJobStore
from apscheduler.jobstores.redis import RedisJobStore
from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.combining import OrTrigger
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.date import DateTrigger
from redis import asyncio as aioredis
from sqlalchemy.engine import create_engine
from sqlalchemy.orm import sessionmaker

import module_task  # noqa: F401
from config.database import AsyncSessionLocal, quote_plus
from config.env import DataBaseConfig, RedisConfig
from module_admin.dao.job_dao import JobDao
from module_admin.entity.vo.job_vo import JobLogModel, JobModel
from module_admin.service.job_log_service import JobLogService
from utils.log_util import logger

# åˆ†å¸ƒå¼é”é…ç½®
SCHEDULER_LOCK_KEY = 'scheduler:leader_lock'
LOCK_EXPIRE_SECONDS = 60  # é”è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
LOCK_RENEWAL_INTERVAL = 20  # é”ç»­æœŸé—´éš”ï¼ˆç§’ï¼‰


# é‡å†™Cronå®šæ—¶
class MyCronTrigger(CronTrigger):
    CRON_EXPRESSION_LENGTH_MIN = 6
    CRON_EXPRESSION_LENGTH_MAX = 7
    WEEKDAY_COUNT = 5

    @classmethod
    def from_crontab(cls, expr: str, timezone: str | None = None) -> 'MyCronTrigger':
        values = expr.split()
        if len(values) != cls.CRON_EXPRESSION_LENGTH_MIN and len(values) != cls.CRON_EXPRESSION_LENGTH_MAX:
            raise ValueError(f'Wrong number of fields; got {len(values)}, expected 6 or 7')

        second = values[0]
        minute = values[1]
        hour = values[2]
        if '?' in values[3]:
            day = None
        elif 'L' in values[5]:
            day = f'last {values[5].replace("L", "")}'
        elif 'W' in values[3]:
            day = cls.__find_recent_workday(int(values[3].split('W')[0]))
        else:
            day = values[3].replace('L', 'last')
        month = values[4]
        if '?' in values[5] or 'L' in values[5]:
            week = None
        elif '#' in values[5]:
            week = int(values[5].split('#')[1])
        else:
            week = values[5]
        day_of_week = int(values[5].split('#')[0]) - 1 if '#' in values[5] else None
        year = values[6] if len(values) == cls.CRON_EXPRESSION_LENGTH_MAX else None
        return cls(
            second=second,
            minute=minute,
            hour=hour,
            day=day,
            month=month,
            week=week,
            day_of_week=day_of_week,
            year=year,
            timezone=timezone,
        )

    @classmethod
    def __find_recent_workday(cls, day: int) -> int:
        now = datetime.now()
        date = datetime(now.year, now.month, day)
        if date.weekday() < cls.WEEKDAY_COUNT:
            return date.day
        diff = 1
        while True:
            previous_day = date - timedelta(days=diff)
            if previous_day.weekday() < cls.WEEKDAY_COUNT:
                return previous_day.day
            diff += 1


SQLALCHEMY_DATABASE_URL = (
    f'mysql+pymysql://{DataBaseConfig.db_username}:{quote_plus(DataBaseConfig.db_password)}@'
    f'{DataBaseConfig.db_host}:{DataBaseConfig.db_port}/{DataBaseConfig.db_database}'
)
if DataBaseConfig.db_type == 'postgresql':
    SQLALCHEMY_DATABASE_URL = (
        f'postgresql+psycopg2://{DataBaseConfig.db_username}:{quote_plus(DataBaseConfig.db_password)}@'
        f'{DataBaseConfig.db_host}:{DataBaseConfig.db_port}/{DataBaseConfig.db_database}'
    )
engine = create_engine(
    SQLALCHEMY_DATABASE_URL,
    echo=DataBaseConfig.db_echo,
    max_overflow=DataBaseConfig.db_max_overflow,
    pool_size=DataBaseConfig.db_pool_size,
    pool_recycle=DataBaseConfig.db_pool_recycle,
    pool_timeout=DataBaseConfig.db_pool_timeout,
)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
redis_config = {
    'host': RedisConfig.redis_host,
    'port': RedisConfig.redis_port,
    'username': RedisConfig.redis_username,
    'password': RedisConfig.redis_password,
    'db': RedisConfig.redis_database,
}
job_stores = {
    'default': MemoryJobStore(),
    'sqlalchemy': SQLAlchemyJobStore(url=SQLALCHEMY_DATABASE_URL, engine=engine),
    'redis': RedisJobStore(**redis_config),
}
executors = {'default': AsyncIOExecutor(), 'processpool': ProcessPoolExecutor(5)}
job_defaults = {'coalesce': False, 'max_instance': 1}
scheduler = AsyncIOScheduler()
scheduler.configure(jobstores=job_stores, executors=executors, job_defaults=job_defaults)


class SchedulerUtil:
    """
    å®šæ—¶ä»»åŠ¡ç›¸å…³æ–¹æ³•
    """

    # åˆ†å¸ƒå¼é”ç›¸å…³ç±»å˜é‡
    _is_leader: bool = False
    _worker_id: str = str(uuid.uuid4())
    _redis: aioredis.Redis | None = None

    @classmethod
    async def init_system_scheduler(cls, redis: aioredis.Redis) -> None:
        """
        åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–å®šæ—¶ä»»åŠ¡ï¼ˆä½¿ç”¨åˆ†å¸ƒå¼é”ç¡®ä¿åªæœ‰ä¸€ä¸ªworkerå¯åŠ¨schedulerï¼‰

        :param redis: Redisè¿æ¥å¯¹è±¡
        :return:
        """
        cls._redis = redis
        logger.info(f'ğŸ” Worker {cls._worker_id[:8]} å°è¯•è·å– Scheduler Leader é”...')

        # å°è¯•è·å–åˆ†å¸ƒå¼é” (SET NX EX)
        acquired = await redis.set(
            SCHEDULER_LOCK_KEY,
            cls._worker_id,
            nx=True,
            ex=LOCK_EXPIRE_SECONDS,
        )

        if acquired:
            cls._is_leader = True
            logger.info(f'ğŸ¯ Worker {cls._worker_id[:8]} æˆä¸º Scheduler Leaderï¼Œå¼€å§‹å¯åŠ¨å®šæ—¶ä»»åŠ¡...')
            scheduler.start()

            # åŠ è½½æ•°æ®åº“ä¸­çš„å®šæ—¶ä»»åŠ¡
            async with AsyncSessionLocal() as session:
                job_list = await JobDao.get_job_list_for_scheduler(session)
                for item in job_list:
                    cls._add_job_to_scheduler(item)

            # æ·»åŠ äº‹ä»¶ç›‘å¬å™¨
            scheduler.add_listener(cls.scheduler_event_listener, EVENT_ALL)

            # æ·»åŠ é”ç»­æœŸä»»åŠ¡
            scheduler.add_job(
                func=cls._renew_scheduler_lock,
                trigger='interval',
                seconds=LOCK_RENEWAL_INTERVAL,
                id='_scheduler_lock_renewal',
                name='Scheduleré”ç»­æœŸä»»åŠ¡',
                replace_existing=True,
            )

            # æ·»åŠ ä»»åŠ¡çŠ¶æ€åŒæ­¥ä»»åŠ¡ï¼ˆæ¯30ç§’ä»æ•°æ®åº“åŒæ­¥ä¸€æ¬¡ä»»åŠ¡çŠ¶æ€ï¼‰
            scheduler.add_job(
                func=cls._sync_jobs_from_database,
                trigger='interval',
                seconds=30,
                id='_scheduler_job_sync',
                name='Schedulerä»»åŠ¡åŒæ­¥',
                replace_existing=True,
            )

            logger.info('âœ…ï¸ ç³»ç»Ÿåˆå§‹å®šæ—¶ä»»åŠ¡åŠ è½½æˆåŠŸ')
        else:
            cls._is_leader = False
            logger.info(f'â¸ï¸ Worker {cls._worker_id[:8]} ä¸æ˜¯ Leaderï¼Œè·³è¿‡ Scheduler å¯åŠ¨')

    @classmethod
    async def _renew_scheduler_lock(cls) -> None:
        """
        ç»­æœŸåˆ†å¸ƒå¼é”ï¼Œç¡®ä¿leaderèº«ä»½ä¸ä¸¢å¤±
        """
        if cls._redis and cls._is_leader:
            # æ£€æŸ¥é”æ˜¯å¦ä»å±äºå½“å‰worker
            current_holder = await cls._redis.get(SCHEDULER_LOCK_KEY)
            if current_holder == cls._worker_id:
                await cls._redis.expire(SCHEDULER_LOCK_KEY, LOCK_EXPIRE_SECONDS)
                logger.debug('ğŸ”„ Scheduler Leader é”ç»­æœŸæˆåŠŸ')
            else:
                # é”è¢«å…¶ä»–workerè·å–ï¼Œå½“å‰workerä¸å†æ˜¯leader
                cls._is_leader = False
                logger.warning(f'âš ï¸ Worker {cls._worker_id[:8]} å¤±å» Leader èº«ä»½')

    @classmethod
    async def _sync_jobs_from_database(cls) -> None:
        """
        ä»æ•°æ®åº“åŒæ­¥ä»»åŠ¡çŠ¶æ€ï¼Œç¡®ä¿å¤šworkerç¯å¢ƒä¸‹ä»»åŠ¡çŠ¶æ€ä¸€è‡´
        """
        if not cls._is_leader:
            return

        try:
            async with AsyncSessionLocal() as session:
                # è·å–æ•°æ®åº“ä¸­æ‰€æœ‰å¯ç”¨çš„ä»»åŠ¡
                db_jobs = await JobDao.get_job_list_for_scheduler(session)
                db_job_ids = {str(job.job_id) for job in db_jobs}
                db_job_map = {str(job.job_id): job for job in db_jobs}

                # è·å–è°ƒåº¦å™¨ä¸­å½“å‰è¿è¡Œçš„ä»»åŠ¡ï¼ˆæ’é™¤å†…éƒ¨ä»»åŠ¡ï¼‰
                scheduler_jobs = scheduler.get_jobs()
                scheduler_job_ids = {job.id for job in scheduler_jobs if not job.id.startswith('_')}

                # æ‰¾å‡ºéœ€è¦ç§»é™¤çš„ä»»åŠ¡ï¼ˆè°ƒåº¦å™¨ä¸­æœ‰ä½†æ•°æ®åº“ä¸­æ²¡æœ‰å¯ç”¨çš„ï¼‰
                jobs_to_remove = scheduler_job_ids - db_job_ids
                for job_id in jobs_to_remove:
                    scheduler.remove_job(job_id=job_id)
                    logger.info(f'ğŸ—‘ï¸ åŒæ­¥ç§»é™¤ä»»åŠ¡: {job_id}')

                # æ‰¾å‡ºéœ€è¦æ·»åŠ çš„ä»»åŠ¡ï¼ˆæ•°æ®åº“ä¸­æœ‰ä½†è°ƒåº¦å™¨ä¸­æ²¡æœ‰çš„ï¼‰
                jobs_to_add = db_job_ids - scheduler_job_ids
                for job_id in jobs_to_add:
                    job_info = db_job_map.get(job_id)
                    if job_info:
                        cls._add_job_to_scheduler(job_info)
                        logger.info(f'â• åŒæ­¥æ·»åŠ ä»»åŠ¡: {job_info.job_name}')

        except Exception as e:
            logger.error(f'âŒ ä»»åŠ¡åŒæ­¥å¼‚å¸¸: {e}')

    @classmethod
    def _prepare_scheduler_job_add(cls, job_info: JobModel) -> dict[str, Any]:
        job_func = cls._import_function(job_info.invoke_target)
        job_executor = job_info.job_executor
        if iscoroutinefunction(job_func):
            job_executor = 'default'
        return {
            'func': job_func,
            'trigger': MyCronTrigger.from_crontab(job_info.cron_expression),
            'args': job_info.job_args.split(',') if job_info.job_args else None,
            'kwargs': json.loads(job_info.job_kwargs) if job_info.job_kwargs else None,
            'id': str(job_info.job_id),
            'name': job_info.job_name,
            'misfire_grace_time': 1000000000000 if job_info.misfire_policy == '3' else None,
            'coalesce': job_info.misfire_policy == '2',
            'max_instances': 3 if job_info.concurrent == '0' else 1,
            'jobstore': job_info.job_group,
            'executor': job_executor,
        }

    @classmethod
    def _add_job_to_scheduler(cls, job_info: JobModel) -> None:
        """
        å†…éƒ¨æ–¹æ³•ï¼šå°†ä»»åŠ¡æ·»åŠ åˆ°è°ƒåº¦å™¨ï¼ˆä¸æ£€æŸ¥ Leader çŠ¶æ€ï¼Œä»…ä¾›å†…éƒ¨ä½¿ç”¨ï¼‰

        :param job_info: ä»»åŠ¡å¯¹è±¡ä¿¡æ¯
        """
        try:
            # å…ˆç§»é™¤å·²å­˜åœ¨çš„åŒIDä»»åŠ¡
            existing_job = scheduler.get_job(job_id=str(job_info.job_id))
            if existing_job:
                scheduler.remove_job(job_id=str(job_info.job_id))
            scheduler.add_job(**cls._prepare_scheduler_job_add(job_info))
        except Exception as e:
            logger.error(f'âŒ æ·»åŠ ä»»åŠ¡ {job_info.job_name} å¤±è´¥: {e}')

    @classmethod
    async def close_system_scheduler(cls) -> None:
        """
        åº”ç”¨å…³é—­æ—¶å…³é—­å®šæ—¶ä»»åŠ¡

        :return:
        """
        if cls._is_leader:
            scheduler.shutdown()
            # é‡Šæ”¾é”
            if cls._redis:
                current_holder = await cls._redis.get(SCHEDULER_LOCK_KEY)
                if current_holder == cls._worker_id:
                    await cls._redis.delete(SCHEDULER_LOCK_KEY)
                    logger.info(f'ğŸ”“ Worker {cls._worker_id[:8]} é‡Šæ”¾ Scheduler Leader é”')
            logger.info('âœ…ï¸ å…³é—­å®šæ—¶ä»»åŠ¡æˆåŠŸ')
        else:
            logger.info(f'â¸ï¸ Worker {cls._worker_id[:8]} ä¸æ˜¯ Leaderï¼Œæ— éœ€å…³é—­ Scheduler')

    @classmethod
    def _import_function(cls, func_path: str) -> Callable[..., Any]:
        """
        åŠ¨æ€å¯¼å…¥å‡½æ•°

        :param func_path: å‡½æ•°å­—ç¬¦ä¸²ï¼Œå¦‚module_task.scheduler_test.job
        :return: å¯¼å…¥çš„å‡½æ•°å¯¹è±¡
        """
        module_path, func_name = func_path.rsplit('.', 1)
        module = importlib.import_module(module_path)
        return getattr(module, func_name)

    @classmethod
    def get_scheduler_job(cls, job_id: str | int) -> Job:
        """
        æ ¹æ®ä»»åŠ¡idè·å–ä»»åŠ¡å¯¹è±¡

        :param job_id: ä»»åŠ¡id
        :return: ä»»åŠ¡å¯¹è±¡
        """
        query_job = scheduler.get_job(job_id=str(job_id))

        return query_job

    @classmethod
    def add_scheduler_job(cls, job_info: JobModel) -> None:
        """
        æ ¹æ®è¾“å…¥çš„ä»»åŠ¡å¯¹è±¡ä¿¡æ¯æ·»åŠ ä»»åŠ¡

        :param job_info: ä»»åŠ¡å¯¹è±¡ä¿¡æ¯
        :return:
        """
        # é Leader worker è·³è¿‡æ“ä½œï¼ˆæ•°æ®åº“çŠ¶æ€æ˜¯æŒä¹…åŒ–çš„ï¼ŒLeader å¯åŠ¨æ—¶ä¼šåŠ è½½ï¼‰
        if not cls._is_leader:
            return
        scheduler.add_job(**cls._prepare_scheduler_job_add(job_info))

    @classmethod
    def execute_scheduler_job_once(cls, job_info: JobModel) -> None:
        """
        æ ¹æ®è¾“å…¥çš„ä»»åŠ¡å¯¹è±¡æ‰§è¡Œä¸€æ¬¡ä»»åŠ¡

        :param job_info: ä»»åŠ¡å¯¹è±¡ä¿¡æ¯
        :return:
        """
        job_func = cls._import_function(job_info.invoke_target)
        job_executor = job_info.job_executor
        if iscoroutinefunction(job_func):
            job_executor = 'default'

        # é Leader workerï¼šç›´æ¥æ‰§è¡Œå‡½æ•°ï¼ˆä¸é€šè¿‡ schedulerï¼‰
        if not cls._is_leader:
            logger.info(f'ğŸ“ å½“å‰ Worker ä¸æ˜¯ Leaderï¼Œç›´æ¥æ‰§è¡Œä»»åŠ¡ {job_info.job_name}')
            try:
                args = job_info.job_args.split(',') if job_info.job_args else []
                kwargs = json.loads(job_info.job_kwargs) if job_info.job_kwargs else {}
                if iscoroutinefunction(job_func):
                    asyncio.create_task(job_func(*args, **kwargs))  # noqa: RUF006
                else:
                    job_func(*args, **kwargs)
            except Exception as e:
                logger.error(f'âŒ ç›´æ¥æ‰§è¡Œä»»åŠ¡ {job_info.job_name} å¤±è´¥: {e}')
            return

        # Leader workerï¼šé€šè¿‡ scheduler æ‰§è¡Œ
        job_trigger = DateTrigger()
        if job_info.status == '0':
            job_trigger = OrTrigger(triggers=[DateTrigger(), MyCronTrigger.from_crontab(job_info.cron_expression)])
        scheduler.add_job(
            func=job_func,
            trigger=job_trigger,
            args=job_info.job_args.split(',') if job_info.job_args else None,
            kwargs=json.loads(job_info.job_kwargs) if job_info.job_kwargs else None,
            id=str(job_info.job_id),
            name=job_info.job_name,
            misfire_grace_time=1000000000000 if job_info.misfire_policy == '3' else None,
            coalesce=job_info.misfire_policy == '2',
            max_instances=3 if job_info.concurrent == '0' else 1,
            jobstore=job_info.job_group,
            executor=job_executor,
        )

    @classmethod
    def remove_scheduler_job(cls, job_id: str | int) -> None:
        """
        æ ¹æ®ä»»åŠ¡idç§»é™¤ä»»åŠ¡

        :param job_id: ä»»åŠ¡id
        :return:
        """
        # é Leader worker è·³è¿‡æ“ä½œï¼ˆæ•°æ®åº“çŠ¶æ€æ˜¯æŒä¹…åŒ–çš„ï¼ŒLeader å¯åŠ¨æ—¶ä¼šæ ¹æ®çŠ¶æ€åŠ è½½ï¼‰
        if not cls._is_leader:
            return
        query_job = cls.get_scheduler_job(job_id=job_id)
        if query_job:
            scheduler.remove_job(job_id=str(job_id))

    @classmethod
    def scheduler_event_listener(cls, event: SchedulerEvent) -> None:
        """
        è°ƒåº¦å™¨äº‹ä»¶ç›‘å¬å™¨ï¼Œè®°å½•ä»»åŠ¡æ‰§è¡Œæ—¥å¿—
        """
        try:
            # è·å–äº‹ä»¶ç±»å‹å’Œä»»åŠ¡ID
            event_type = event.__class__.__name__
            # è·å–ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸ä¿¡æ¯
            status = '0'
            exception_info = ''
            if event_type == 'JobExecutionEvent' and event.exception:
                exception_info = str(event.exception)
                status = '1'
            if hasattr(event, 'job_id'):
                job_id = event.job_id
                # è·³è¿‡å†…éƒ¨ç³»ç»Ÿä»»åŠ¡ï¼ˆä»¥ _ å¼€å¤´çš„ä»»åŠ¡IDï¼‰ï¼Œä¸è®°å½•æ—¥å¿—
                if str(job_id).startswith('_'):
                    return
                query_job = cls.get_scheduler_job(job_id=job_id)
                if query_job:
                    query_job_info = query_job.__getstate__()
                    # è·å–ä»»åŠ¡åç§°
                    job_name = query_job_info.get('name')
                    # è·å–ä»»åŠ¡ç»„å
                    job_group = query_job._jobstore_alias
                    # è·å–ä»»åŠ¡æ‰§è¡Œå™¨
                    job_executor = query_job_info.get('executor')
                    # è·å–è°ƒç”¨ç›®æ ‡å­—ç¬¦ä¸²
                    invoke_target = query_job_info.get('func')
                    # è·å–è°ƒç”¨å‡½æ•°ä½ç½®å‚æ•°ï¼ˆå®‰å…¨å¤„ç†ï¼‰
                    args = query_job_info.get('args')
                    job_args = ','.join(str(arg) for arg in args) if args else ''
                    # è·å–è°ƒç”¨å‡½æ•°å…³é”®å­—å‚æ•°
                    kwargs = query_job_info.get('kwargs')
                    job_kwargs = json.dumps(kwargs) if kwargs else '{}'
                    # è·å–ä»»åŠ¡è§¦å‘å™¨
                    job_trigger = str(query_job_info.get('trigger'))
                    # æ„é€ æ—¥å¿—æ¶ˆæ¯
                    job_message = f'äº‹ä»¶ç±»å‹: {event_type}, ä»»åŠ¡ID: {job_id}, ä»»åŠ¡åç§°: {job_name}, æ‰§è¡Œäº{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}'
                    job_log = JobLogModel(
                        jobName=job_name,
                        jobGroup=job_group,
                        jobExecutor=job_executor,
                        invokeTarget=invoke_target,
                        jobArgs=job_args,
                        jobKwargs=job_kwargs,
                        jobTrigger=job_trigger,
                        jobMessage=job_message,
                        status=status,
                        exceptionInfo=exception_info,
                        createTime=datetime.now(),
                    )
                    session = SessionLocal()
                    try:
                        JobLogService.add_job_log_services(session, job_log)
                    finally:
                        session.close()
        except Exception as e:
            logger.error(f'âŒ è°ƒåº¦ä»»åŠ¡äº‹ä»¶ç›‘å¬å™¨å¼‚å¸¸: {e}')
