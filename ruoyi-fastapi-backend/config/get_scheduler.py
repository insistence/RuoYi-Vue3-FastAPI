import asyncio
import importlib
import json
from asyncio import iscoroutinefunction
from collections.abc import Callable
from datetime import datetime, timedelta
from typing import Any

from apscheduler.events import EVENT_ALL, SchedulerEvent
from apscheduler.executors.asyncio import AsyncIOExecutor
from apscheduler.executors.pool import ProcessPoolExecutor
from apscheduler.job import Job
from apscheduler.jobstores.memory import MemoryJobStore
from apscheduler.jobstores.redis import RedisJobStore
from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.combining import OrTrigger
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.date import DateTrigger
from redis import asyncio as aioredis
from sqlalchemy.engine import Engine
from sqlalchemy.ext.asyncio import AsyncEngine

import module_task  # noqa: F401
from common.constant import LockConstant
from config.database import (
    SYNC_SQLALCHEMY_DATABASE_URL,
    create_async_db_engine,
    create_async_session_local,
    create_sync_db_engine,
    create_sync_session_local,
)
from config.env import AppConfig, LogConfig, RedisConfig
from module_admin.dao.job_dao import JobDao
from module_admin.entity.vo.job_vo import JobLogModel, JobModel
from module_admin.service.job_log_service import JobLogService
from utils.log_util import logger
from utils.server_util import StartupUtil, WorkerIdUtil


# é‡å†™Cronå®šæ—¶
class MyCronTrigger(CronTrigger):
    CRON_EXPRESSION_LENGTH_MIN = 6
    CRON_EXPRESSION_LENGTH_MAX = 7
    WEEKDAY_COUNT = 5

    @classmethod
    def from_crontab(cls, expr: str, timezone: str | None = None) -> 'MyCronTrigger':
        values = expr.split()
        if len(values) != cls.CRON_EXPRESSION_LENGTH_MIN and len(values) != cls.CRON_EXPRESSION_LENGTH_MAX:
            raise ValueError(f'Wrong number of fields; got {len(values)}, expected 6 or 7')

        second = values[0]
        minute = values[1]
        hour = values[2]
        if '?' in values[3]:
            day = None
        elif 'L' in values[5]:
            day = f'last {values[5].replace("L", "")}'
        elif 'W' in values[3]:
            day = cls.__find_recent_workday(int(values[3].split('W')[0]))
        else:
            day = values[3].replace('L', 'last')
        month = values[4]
        if '?' in values[5] or 'L' in values[5]:
            week = None
        elif '#' in values[5]:
            week = int(values[5].split('#')[1])
        else:
            week = values[5]
        day_of_week = int(values[5].split('#')[0]) - 1 if '#' in values[5] else None
        year = values[6] if len(values) == cls.CRON_EXPRESSION_LENGTH_MAX else None
        return cls(
            second=second,
            minute=minute,
            hour=hour,
            day=day,
            month=month,
            week=week,
            day_of_week=day_of_week,
            year=year,
            timezone=timezone,
        )

    @classmethod
    def __find_recent_workday(cls, day: int) -> int:
        now = datetime.now()
        date = datetime(now.year, now.month, day)
        if date.weekday() < cls.WEEKDAY_COUNT:
            return date.day
        diff = 1
        while True:
            previous_day = date - timedelta(days=diff)
            if previous_day.weekday() < cls.WEEKDAY_COUNT:
                return previous_day.day
            diff += 1


redis_config = {
    'host': RedisConfig.redis_host,
    'port': RedisConfig.redis_port,
    'username': RedisConfig.redis_username,
    'password': RedisConfig.redis_password,
    'db': RedisConfig.redis_database,
}
job_defaults = {'coalesce': False, 'max_instance': 1}
scheduler = AsyncIOScheduler()


class SchedulerUtil:
    """
    å®šæ—¶ä»»åŠ¡ç›¸å…³æ–¹æ³•
    """

    # åˆ†å¸ƒå¼é”ç›¸å…³ç±»å˜é‡
    _is_leader: bool = False
    _worker_id: str = WorkerIdUtil.get_worker_id(LogConfig.log_worker_id)
    _redis: aioredis.Redis | None = None
    _job_update_time_cache: dict[str, datetime] = {}
    _sync_channel: str = 'scheduler:sync:request'
    _sync_listener_task: asyncio.Task | None = None
    _lock_lost_task: asyncio.Task | None = None
    _sync_task: asyncio.Task | None = None
    _sync_pending: bool = False
    _sync_lock: asyncio.Lock = asyncio.Lock()
    _last_sync_at: datetime | None = None
    _sync_debounce_seconds: float = 0.5
    _sync_min_interval_seconds: float = 2.0
    _reacquire_task: asyncio.Task | None = None
    _reacquire_interval_seconds: float = 5.0
    _sync_async_engine: AsyncEngine | None = None
    _sync_async_sessionmaker: Any | None = None
    _disposed_sync_engines: bool = False

    # æ‡’åŠ è½½çš„åŒæ­¥ Engine å’Œ SessionLocal
    _jobstore_engine: Engine | None = None
    _listener_engine: Engine | None = None
    _session_local: Any | None = None
    _scheduler_configured: bool = False

    @classmethod
    def _get_jobstore_engine(cls) -> Engine:
        """
        æ‡’åŠ è½½è·å– jobstore ä½¿ç”¨çš„åŒæ­¥ Engine

        :return: åŒæ­¥ Engine
        """
        if cls._jobstore_engine is None:
            cls._jobstore_engine = create_sync_db_engine(echo=False)
        return cls._jobstore_engine

    @classmethod
    def _get_listener_engine(cls) -> Engine:
        """
        æ‡’åŠ è½½è·å– listener ä½¿ç”¨çš„åŒæ­¥ Engine

        :return: åŒæ­¥ Engine
        """
        if cls._listener_engine is None:
            cls._listener_engine = create_sync_db_engine()
        return cls._listener_engine

    @classmethod
    def _get_session_local(cls) -> Any:
        """
        æ‡’åŠ è½½è·å–åŒæ­¥ SessionLocal

        :return: SessionLocal
        """
        if cls._session_local is None:
            cls._session_local = create_sync_session_local(cls._get_listener_engine())
        return cls._session_local

    @classmethod
    def _configure_scheduler(cls) -> None:
        """
        é…ç½® schedulerï¼ˆæ‡’åŠ è½½ jobstoreï¼‰

        :return: None
        """
        if cls._scheduler_configured:
            return
        job_stores = {
            'default': MemoryJobStore(),
            'sqlalchemy': SQLAlchemyJobStore(url=SYNC_SQLALCHEMY_DATABASE_URL, engine=cls._get_jobstore_engine()),
            'redis': RedisJobStore(**redis_config),
        }
        executors = {'default': AsyncIOExecutor(), 'processpool': ProcessPoolExecutor(5)}
        scheduler.configure(jobstores=job_stores, executors=executors, job_defaults=job_defaults)
        cls._scheduler_configured = True

    @classmethod
    def _should_enable_scheduler_sync(cls) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦å¯ç”¨å¤š worker çš„ä»»åŠ¡çŠ¶æ€åŒæ­¥æœºåˆ¶

        :return: æ˜¯å¦å¼€å¯å®šæ—¶åŒæ­¥ä¸ç›‘å¬
        """
        return not AppConfig.app_reload and AppConfig.app_workers > 1

    @classmethod
    async def init_system_scheduler(cls, redis: aioredis.Redis) -> None:
        """
        åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–å®šæ—¶ä»»åŠ¡ï¼ˆä½¿ç”¨åˆ†å¸ƒå¼é”ç¡®ä¿åªæœ‰ä¸€ä¸ªworkerå¯åŠ¨schedulerï¼‰

        :param redis: Redisè¿æ¥å¯¹è±¡
        :return:
        """
        cls._redis = redis
        logger.info(f'ğŸ” Worker {cls._worker_id} å°è¯•è·å– Application é”...')

        acquired = await StartupUtil.acquire_startup_log_gate(
            redis=redis,
            lock_key=LockConstant.APP_STARTUP_LOCK_KEY,
            worker_id=cls._worker_id,
            lock_expire_seconds=LockConstant.LOCK_EXPIRE_SECONDS,
        )

        if acquired:
            await cls._start_scheduler_as_leader(redis)
        else:
            cls._is_leader = False
            logger.info(f'â¸ï¸ Worker {cls._worker_id} æœªæŒæœ‰ Application é”ï¼Œè·³è¿‡ Scheduler å¯åŠ¨')

    @classmethod
    async def _start_scheduler_as_leader(cls, redis: aioredis.Redis) -> None:
        """
        ä»¥ Leader èº«ä»½å¯åŠ¨ Schedulerï¼ˆå†…éƒ¨æ–¹æ³•ï¼Œè°ƒç”¨å‰éœ€ç¡®ä¿å·²æŒæœ‰é”ï¼‰

        :param redis: Redisè¿æ¥å¯¹è±¡
        :return: None
        """
        cls._is_leader = True
        cls._disposed_sync_engines = False
        logger.info(f'ğŸ¯ Worker {cls._worker_id} æŒæœ‰ Application é”ï¼Œå¼€å§‹å¯åŠ¨å®šæ—¶ä»»åŠ¡...')
        # æ‡’åŠ è½½é…ç½® scheduler
        cls._configure_scheduler()
        scheduler.start()

        # åŠ è½½æ•°æ®åº“ä¸­çš„å®šæ—¶ä»»åŠ¡
        async with cls._get_sync_async_session() as session:
            job_list = await JobDao.get_job_list_for_scheduler(session)
            for item in job_list:
                cls._add_job_to_scheduler(item)

        # æ·»åŠ äº‹ä»¶ç›‘å¬å™¨
        scheduler.add_listener(cls.scheduler_event_listener, EVENT_ALL)

        if cls._should_enable_scheduler_sync():
            # æ·»åŠ ä»»åŠ¡çŠ¶æ€åŒæ­¥ä»»åŠ¡ï¼ˆæ¯30ç§’ä»æ•°æ®åº“åŒæ­¥ä¸€æ¬¡ä»»åŠ¡çŠ¶æ€ï¼‰
            scheduler.add_job(
                func=cls.request_scheduler_sync,
                trigger='interval',
                seconds=30,
                id='_scheduler_job_sync',
                name='Schedulerä»»åŠ¡åŒæ­¥',
                replace_existing=True,
            )
            cls._sync_listener_task = asyncio.create_task(cls._listen_sync_channel(redis))

        logger.info('âœ…ï¸ ç³»ç»Ÿåˆå§‹å®šæ—¶ä»»åŠ¡åŠ è½½æˆåŠŸ')

    @classmethod
    def on_lock_lost(cls) -> None:
        """
        é”ä¸¢å¤±å¤„ç†å…¥å£

        :return: None
        """
        if not cls._is_leader:
            return
        cls._is_leader = False
        logger.warning(f'âš ï¸ Worker {cls._worker_id} å¤±å» Application é”')
        if cls._lock_lost_task:
            cls._lock_lost_task.cancel()
        cls._lock_lost_task = asyncio.create_task(cls._handle_lock_lost())

    @classmethod
    async def _handle_lock_lost(cls) -> None:
        """
        å¤„ç†é”ä¸¢å¤±åçš„èµ„æºé‡Šæ”¾

        :return: None
        """
        if cls._sync_listener_task:
            cls._sync_listener_task.cancel()
            try:
                await cls._sync_listener_task
            except asyncio.CancelledError:
                pass
            cls._sync_listener_task = None
        if cls._sync_task:
            cls._sync_task.cancel()
            try:
                await cls._sync_task
            except asyncio.CancelledError:
                pass
            cls._sync_task = None
            cls._sync_pending = False
        if getattr(scheduler, 'running', False):
            scheduler.shutdown()
        await cls._dispose_sync_async_engine()
        cls._dispose_sync_engines()
        cls._ensure_reacquire_task()

    @classmethod
    async def _sync_jobs_from_database(cls) -> None:
        """
        ä»æ•°æ®åº“åŒæ­¥ä»»åŠ¡çŠ¶æ€ï¼Œç¡®ä¿å¤šworkerç¯å¢ƒä¸‹ä»»åŠ¡çŠ¶æ€ä¸€è‡´
        """
        if not cls._is_leader:
            return

        try:
            async with cls._get_sync_async_session() as session:
                db_jobs_all = await JobDao.get_all_job_list_for_scheduler(session)
                db_jobs_enabled = [job for job in db_jobs_all if job.status == '0']
                db_enabled_ids = {str(job.job_id) for job in db_jobs_enabled}
                db_job_map = {str(job.job_id): job for job in db_jobs_enabled}
                db_job_update_time_map = {
                    str(job.job_id): job.update_time for job in db_jobs_enabled if job.update_time is not None
                }
                scheduler_jobs = scheduler.get_jobs()
                scheduler_job_map = {job.id: job for job in scheduler_jobs if not job.id.startswith('_')}
                scheduler_job_ids = set(scheduler_job_map.keys())

                jobs_to_remove = scheduler_job_ids - db_enabled_ids
                for job_id in jobs_to_remove:
                    scheduler.remove_job(job_id=job_id)
                    logger.info(f'ğŸ—‘ï¸ åŒæ­¥ç§»é™¤ä»»åŠ¡: {job_id}')
                    cls._refresh_job_update_cache(job_id, None)

                jobs_to_add = db_enabled_ids - scheduler_job_ids
                for job_id in jobs_to_add:
                    job_info = db_job_map.get(job_id)
                    if job_info:
                        cls._add_job_to_scheduler(job_info)
                        logger.info(f'â• åŒæ­¥æ·»åŠ ä»»åŠ¡: {job_info.job_name}')
                        cls._refresh_job_update_cache(job_id, job_info.update_time)

                jobs_to_update = db_enabled_ids & scheduler_job_ids
                for job_id in jobs_to_update:
                    job_info = db_job_map.get(job_id)
                    scheduler_job = scheduler_job_map.get(job_id)
                    job_update_time = db_job_update_time_map.get(job_id)
                    cls._sync_update_job(job_id, job_info, scheduler_job, job_update_time)

        except Exception as e:
            logger.error(f'âŒ ä»»åŠ¡åŒæ­¥å¼‚å¸¸: {e}')

    @classmethod
    def _is_job_config_in_sync(cls, scheduler_job: Job, job_info: JobModel) -> bool:
        """
        åˆ¤æ–­ä»»åŠ¡é…ç½®æ˜¯å¦ä¸€è‡´

        :param scheduler_job: è°ƒåº¦å™¨ä»»åŠ¡å¯¹è±¡
        :param job_info: æ•°æ®åº“ä»»åŠ¡å¯¹è±¡
        :return: æ˜¯å¦ä¸€è‡´
        """
        job_state = scheduler_job.__getstate__()
        job_kwargs = json.loads(job_info.job_kwargs) if job_info.job_kwargs else None
        job_args = job_info.job_args.split(',') if job_info.job_args else None
        job_executor = job_info.job_executor
        if iscoroutinefunction(cls._import_function(job_info.invoke_target)):
            job_executor = 'default'
        expected = {
            'name': job_info.job_name,
            'executor': job_executor,
            'jobstore': job_info.job_group,
            'misfire_grace_time': 1000000000000 if job_info.misfire_policy == '3' else None,
            'coalesce': job_info.misfire_policy == '2',
            'max_instances': 3 if job_info.concurrent == '0' else 1,
            'trigger': str(MyCronTrigger.from_crontab(job_info.cron_expression)),
            'args': tuple(job_args) if job_args else None,
            'kwargs': job_kwargs if job_kwargs else None,
            'func': str(cls._import_function(job_info.invoke_target)),
        }
        current = {
            'name': job_state.get('name'),
            'executor': job_state.get('executor'),
            'jobstore': scheduler_job._jobstore_alias,
            'misfire_grace_time': job_state.get('misfire_grace_time'),
            'coalesce': job_state.get('coalesce'),
            'max_instances': job_state.get('max_instances'),
            'trigger': str(job_state.get('trigger')),
            'args': job_state.get('args'),
            'kwargs': job_state.get('kwargs'),
            'func': str(job_state.get('func')),
        }
        return expected == current

    @classmethod
    def _sync_update_job(
        cls, job_id: str, job_info: JobModel | None, scheduler_job: Job | None, job_update_time: datetime | None
    ) -> None:
        """
        åŒæ­¥æ›´æ–°ä»»åŠ¡é…ç½®

        :param job_id: ä»»åŠ¡ID
        :param job_info: æ•°æ®åº“ä»»åŠ¡å¯¹è±¡
        :param scheduler_job: è°ƒåº¦å™¨ä»»åŠ¡å¯¹è±¡
        :param job_update_time: ä»»åŠ¡æ›´æ–°æ—¶é—´
        :return: None
        """
        if not job_info or not scheduler_job:
            return
        if cls._should_skip_job_update(job_id, job_update_time):
            return
        if not cls._is_job_config_in_sync(scheduler_job, job_info):
            scheduler.remove_job(job_id=job_id)
            cls._add_job_to_scheduler(job_info)
            logger.info(f'â™»ï¸ åŒæ­¥æ›´æ–°ä»»åŠ¡: {job_info.job_name}')
        cls._refresh_job_update_cache(job_id, job_update_time)

    @classmethod
    def _should_skip_job_update(cls, job_id: str, job_update_time: datetime | None) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦è·³è¿‡åŒæ­¥æ›´æ–°

        :param job_id: ä»»åŠ¡ID
        :param job_update_time: ä»»åŠ¡æ›´æ–°æ—¶é—´
        :return: æ˜¯å¦è·³è¿‡
        """
        if job_update_time is None:
            return False
        return cls._job_update_time_cache.get(job_id) == job_update_time

    @classmethod
    def _refresh_job_update_cache(cls, job_id: str, job_update_time: datetime | None) -> None:
        """
        åˆ·æ–°ä»»åŠ¡æ›´æ–°æ—¶é—´ç¼“å­˜

        :param job_id: ä»»åŠ¡ID
        :param job_update_time: ä»»åŠ¡æ›´æ–°æ—¶é—´
        :return: None
        """
        if job_update_time is not None:
            cls._job_update_time_cache[job_id] = job_update_time
        else:
            cls._job_update_time_cache.pop(job_id, None)

    @classmethod
    async def request_scheduler_sync(cls) -> None:
        """
        è¯·æ±‚è°ƒåº¦å™¨åŒæ­¥ä»»åŠ¡çŠ¶æ€

        :return: None
        """
        if cls._is_leader:
            cls._sync_pending = True
            cls._ensure_sync_task()
            return
        if cls._redis:
            await cls._redis.publish(cls._sync_channel, cls._worker_id)

    @classmethod
    def _ensure_sync_task(cls) -> None:
        """
        å¯åŠ¨åŒæ­¥è°ƒåº¦ä»»åŠ¡

        :return: None
        """
        if cls._sync_task and not cls._sync_task.done():
            return
        cls._sync_task = asyncio.create_task(cls._run_sync_loop())

    @classmethod
    def _get_sync_async_session(cls) -> Any:
        """
        è·å–åŒæ­¥ä»»åŠ¡ä½¿ç”¨çš„å¼‚æ­¥ Session

        :return: å¼‚æ­¥ Session
        """
        if not cls._sync_async_sessionmaker:
            cls._sync_async_engine = create_async_db_engine(echo=False)
            cls._sync_async_sessionmaker = create_async_session_local(cls._sync_async_engine)
        return cls._sync_async_sessionmaker()

    @classmethod
    async def _dispose_sync_async_engine(cls) -> None:
        """
        é‡Šæ”¾åŒæ­¥ä»»åŠ¡ä½¿ç”¨çš„å¼‚æ­¥ Engine

        :return: None
        """
        if cls._sync_async_engine:
            await cls._sync_async_engine.dispose()
            cls._sync_async_engine = None
            cls._sync_async_sessionmaker = None

    @classmethod
    def _dispose_sync_engines(cls) -> None:
        """
        é‡Šæ”¾ Scheduler ä½¿ç”¨çš„åŒæ­¥ Engine

        :return: None
        """
        if cls._disposed_sync_engines:
            return
        if cls._jobstore_engine:
            cls._jobstore_engine.dispose()
            cls._jobstore_engine = None
        if cls._listener_engine:
            cls._listener_engine.dispose()
            cls._listener_engine = None
        cls._session_local = None
        cls._disposed_sync_engines = True

    @classmethod
    def _ensure_reacquire_task(cls) -> None:
        """
        å¯åŠ¨é”é‡æ–°ç«äº‰ä»»åŠ¡

        :return: None
        """
        if not cls._redis:
            return
        if cls._reacquire_task and not cls._reacquire_task.done():
            return
        cls._reacquire_task = asyncio.create_task(cls._run_reacquire_loop())

    @classmethod
    async def _run_reacquire_loop(cls) -> None:
        """
        å¾ªç¯å°è¯•é‡æ–°è·å–é”å¹¶æ¢å¤è°ƒåº¦å™¨

        :return: None
        """
        try:
            while not cls._is_leader:
                if not cls._redis:
                    await asyncio.sleep(cls._reacquire_interval_seconds)
                    continue
                acquired = await StartupUtil.acquire_startup_log_gate(
                    redis=cls._redis,
                    lock_key=LockConstant.APP_STARTUP_LOCK_KEY,
                    worker_id=cls._worker_id,
                    lock_expire_seconds=LockConstant.LOCK_EXPIRE_SECONDS,
                )
                if acquired:
                    # ç›´æ¥è°ƒç”¨ _start_scheduler_as_leaderï¼Œé¿å…é‡å¤è·å–é”
                    await cls._start_scheduler_as_leader(cls._redis)
                    return
                await asyncio.sleep(cls._reacquire_interval_seconds)
        except asyncio.CancelledError:
            raise
        finally:
            cls._reacquire_task = None

    @classmethod
    async def _run_sync_loop(cls) -> None:
        """
        æ‰§è¡ŒåŒæ­¥è°ƒåº¦å¾ªç¯

        :return: None
        """
        try:
            while True:
                if not cls._sync_pending:
                    break
                cls._sync_pending = False
                await asyncio.sleep(cls._sync_debounce_seconds)
                await cls._sync_with_throttle()
        except asyncio.CancelledError:
            raise
        finally:
            cls._sync_task = None

    @classmethod
    async def _sync_with_throttle(cls) -> None:
        """
        æŒ‰èŠ‚æµè§„åˆ™æ‰§è¡ŒåŒæ­¥

        :return: None
        """
        async with cls._sync_lock:
            if not cls._is_leader:
                return
            if cls._last_sync_at:
                elapsed = datetime.now() - cls._last_sync_at
                min_interval = timedelta(seconds=cls._sync_min_interval_seconds)
                if elapsed < min_interval:
                    await asyncio.sleep((min_interval - elapsed).total_seconds())
            await cls._sync_jobs_from_database()
            cls._last_sync_at = datetime.now()

    @classmethod
    async def _listen_sync_channel(cls, redis: aioredis.Redis) -> None:
        """
        ç›‘å¬åŒæ­¥è¯·æ±‚é€šé“

        :param redis: Redisè¿æ¥å¯¹è±¡
        :return: None
        """
        while True:
            pubsub = redis.pubsub()
            try:
                await pubsub.subscribe(cls._sync_channel)
                async for message in pubsub.listen():
                    if not cls._is_leader:
                        continue
                    if message.get('type') != 'message':
                        continue
                    await cls.request_scheduler_sync()
            except asyncio.CancelledError:
                await pubsub.unsubscribe(cls._sync_channel)
                await pubsub.close()
                raise
            except Exception as e:
                logger.error(f'âŒ Scheduler åŒæ­¥ç›‘å¬å¼‚å¸¸: {e}ï¼Œ5ç§’åé‡è¯•...')
                await pubsub.close()
                await asyncio.sleep(5)
            finally:
                try:
                    await pubsub.close()
                except Exception:
                    pass

    @classmethod
    async def _execute_async_job_with_log(
        cls, job_func: Callable[..., Any], job_info: JobModel, args: list, kwargs: dict
    ) -> None:
        """
        æ‰§è¡Œå¼‚æ­¥ä»»åŠ¡å¹¶è®°å½•æ—¥å¿—

        :param job_func: ä»»åŠ¡å‡½æ•°
        :param job_info: ä»»åŠ¡å¯¹è±¡ä¿¡æ¯
        :param args: ä½ç½®å‚æ•°
        :param kwargs: å…³é”®å­—å‚æ•°
        :return: None
        """
        status = '0'
        exception_info = ''
        job_executor = job_info.job_executor
        if iscoroutinefunction(job_func):
            job_executor = 'default'
        try:
            await job_func(*args, **kwargs)
        except Exception as e:
            status = '1'
            exception_info = str(e)
            logger.error(f'âŒ å¼‚æ­¥æ‰§è¡Œä»»åŠ¡ {job_info.job_name} å¤±è´¥: {e}')
        finally:
            cls._record_job_execution_log(job_info, job_executor, status, exception_info)

    @classmethod
    def _record_job_execution_log(cls, job_info: JobModel, job_executor: str, status: str, exception_info: str) -> None:
        """
        è®°å½•ä»»åŠ¡æ‰§è¡Œæ—¥å¿—ï¼ˆç”¨äºé Leader Worker ç›´æ¥æ‰§è¡Œä»»åŠ¡æ—¶ï¼‰

        :param job_info: ä»»åŠ¡å¯¹è±¡ä¿¡æ¯
        :param job_executor: ä»»åŠ¡æ‰§è¡Œå™¨
        :param status: æ‰§è¡ŒçŠ¶æ€ 0-æˆåŠŸ 1-å¤±è´¥
        :param exception_info: å¼‚å¸¸ä¿¡æ¯
        :return: None
        """
        try:
            job_args = job_info.job_args if job_info.job_args else ''
            job_kwargs = job_info.job_kwargs if job_info.job_kwargs else '{}'
            job_trigger = str(MyCronTrigger.from_crontab(job_info.cron_expression)) if job_info.cron_expression else ''
            job_message = (
                f'äº‹ä»¶ç±»å‹: DirectExecution(éLeader), ä»»åŠ¡ID: {job_info.job_id}, '
                f'ä»»åŠ¡åç§°: {job_info.job_name}, æ‰§è¡Œäº{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}'
            )
            job_log = JobLogModel(
                jobName=job_info.job_name,
                jobGroup=job_info.job_group,
                jobExecutor=job_executor,
                invokeTarget=job_info.invoke_target,
                jobArgs=job_args,
                jobKwargs=job_kwargs,
                jobTrigger=job_trigger,
                jobMessage=job_message,
                status=status,
                exceptionInfo=exception_info,
                createTime=datetime.now(),
            )
            session = cls._get_session_local()()
            try:
                JobLogService.add_job_log_services(session, job_log)
            finally:
                session.close()
        except Exception as e:
            logger.error(f'âŒ è®°å½•ä»»åŠ¡æ‰§è¡Œæ—¥å¿—å¤±è´¥: {e}')

    @classmethod
    def _prepare_scheduler_job_add(cls, job_info: JobModel) -> dict[str, Any]:
        """
        æ„å»ºè°ƒåº¦å™¨ä»»åŠ¡å‚æ•°

        :param job_info: ä»»åŠ¡å¯¹è±¡ä¿¡æ¯
        :return: è°ƒåº¦å™¨ä»»åŠ¡å‚æ•°
        """
        job_func = cls._import_function(job_info.invoke_target)
        job_executor = job_info.job_executor
        if iscoroutinefunction(job_func):
            job_executor = 'default'
        return {
            'func': job_func,
            'trigger': MyCronTrigger.from_crontab(job_info.cron_expression),
            'args': job_info.job_args.split(',') if job_info.job_args else None,
            'kwargs': json.loads(job_info.job_kwargs) if job_info.job_kwargs else None,
            'id': str(job_info.job_id),
            'name': job_info.job_name,
            'misfire_grace_time': 1000000000000 if job_info.misfire_policy == '3' else None,
            'coalesce': job_info.misfire_policy == '2',
            'max_instances': 3 if job_info.concurrent == '0' else 1,
            'jobstore': job_info.job_group,
            'executor': job_executor,
        }

    @classmethod
    def _add_job_to_scheduler(cls, job_info: JobModel) -> None:
        """
        å†…éƒ¨æ–¹æ³•ï¼šå°†ä»»åŠ¡æ·»åŠ åˆ°è°ƒåº¦å™¨ï¼ˆä¸æ£€æŸ¥åº”ç”¨é”çŠ¶æ€ï¼Œä»…ä¾›å†…éƒ¨ä½¿ç”¨ï¼‰

        :param job_info: ä»»åŠ¡å¯¹è±¡ä¿¡æ¯
        """
        try:
            # å…ˆç§»é™¤å·²å­˜åœ¨çš„åŒIDä»»åŠ¡
            existing_job = scheduler.get_job(job_id=str(job_info.job_id))
            if existing_job:
                scheduler.remove_job(job_id=str(job_info.job_id))
            scheduler.add_job(**cls._prepare_scheduler_job_add(job_info))
        except Exception as e:
            logger.error(f'âŒ æ·»åŠ ä»»åŠ¡ {job_info.job_name} å¤±è´¥: {e}')

    @classmethod
    async def close_system_scheduler(cls) -> None:
        """
        åº”ç”¨å…³é—­æ—¶å…³é—­å®šæ—¶ä»»åŠ¡

        :return:
        """
        if cls._sync_listener_task:
            cls._sync_listener_task.cancel()
            try:
                await cls._sync_listener_task
            except asyncio.CancelledError:
                pass
            cls._sync_listener_task = None
        if cls._sync_task:
            cls._sync_task.cancel()
            try:
                await cls._sync_task
            except asyncio.CancelledError:
                pass
            cls._sync_task = None
            cls._sync_pending = False
        if cls._reacquire_task:
            cls._reacquire_task.cancel()
            try:
                await cls._reacquire_task
            except asyncio.CancelledError:
                pass
            cls._reacquire_task = None
        await cls._dispose_sync_async_engine()
        cls._dispose_sync_engines()
        if cls._lock_lost_task:
            cls._lock_lost_task.cancel()
            try:
                await cls._lock_lost_task
            except asyncio.CancelledError:
                pass
            cls._lock_lost_task = None
        if getattr(scheduler, 'running', False):
            scheduler.shutdown()
            logger.info('âœ…ï¸ å…³é—­å®šæ—¶ä»»åŠ¡æˆåŠŸ')
        # é‡Šæ”¾é”
        if cls._redis:
            current_holder = await cls._redis.get(LockConstant.APP_STARTUP_LOCK_KEY)
            if current_holder == cls._worker_id:
                await cls._redis.delete(LockConstant.APP_STARTUP_LOCK_KEY)
                logger.info(f'ğŸ”“ Worker {cls._worker_id} é‡Šæ”¾ Application é”')

    @classmethod
    def _import_function(cls, func_path: str) -> Callable[..., Any]:
        """
        åŠ¨æ€å¯¼å…¥å‡½æ•°

        :param func_path: å‡½æ•°å­—ç¬¦ä¸²ï¼Œå¦‚module_task.scheduler_test.job
        :return: å¯¼å…¥çš„å‡½æ•°å¯¹è±¡
        """
        module_path, func_name = func_path.rsplit('.', 1)
        module = importlib.import_module(module_path)
        return getattr(module, func_name)

    @classmethod
    def get_scheduler_job(cls, job_id: str | int) -> Job:
        """
        æ ¹æ®ä»»åŠ¡idè·å–ä»»åŠ¡å¯¹è±¡

        :param job_id: ä»»åŠ¡id
        :return: ä»»åŠ¡å¯¹è±¡
        """
        query_job = scheduler.get_job(job_id=str(job_id))

        return query_job

    @classmethod
    def add_scheduler_job(cls, job_info: JobModel) -> None:
        """
        æ ¹æ®è¾“å…¥çš„ä»»åŠ¡å¯¹è±¡ä¿¡æ¯æ·»åŠ ä»»åŠ¡

        :param job_info: ä»»åŠ¡å¯¹è±¡ä¿¡æ¯
        :return:
        """
        # éåº”ç”¨é” worker è·³è¿‡æ“ä½œï¼ˆæ•°æ®åº“çŠ¶æ€æ˜¯æŒä¹…åŒ–çš„ï¼ŒæŒæœ‰åº”ç”¨é”æ—¶ä¼šåŠ è½½ï¼‰
        if not cls._is_leader:
            return
        scheduler.add_job(**cls._prepare_scheduler_job_add(job_info))

    @classmethod
    def execute_scheduler_job_once(cls, job_info: JobModel) -> None:
        """
        æ ¹æ®è¾“å…¥çš„ä»»åŠ¡å¯¹è±¡æ‰§è¡Œä¸€æ¬¡ä»»åŠ¡

        :param job_info: ä»»åŠ¡å¯¹è±¡ä¿¡æ¯
        :return:
        """
        job_func = cls._import_function(job_info.invoke_target)
        job_executor = job_info.job_executor
        if iscoroutinefunction(job_func):
            job_executor = 'default'

        # éåº”ç”¨é” workerï¼šç›´æ¥æ‰§è¡Œå‡½æ•°ï¼ˆä¸é€šè¿‡ schedulerï¼‰
        if not cls._is_leader:
            logger.info(f'ğŸ“ å½“å‰ Worker æœªæŒæœ‰ Application é”ï¼Œç›´æ¥æ‰§è¡Œä»»åŠ¡ {job_info.job_name}')
            args = job_info.job_args.split(',') if job_info.job_args else []
            kwargs = json.loads(job_info.job_kwargs) if job_info.job_kwargs else {}
            status = '0'
            exception_info = ''
            try:
                if iscoroutinefunction(job_func):
                    asyncio.create_task(cls._execute_async_job_with_log(job_func, job_info, args, kwargs))  # noqa: RUF006
                else:
                    job_func(*args, **kwargs)
            except Exception as e:
                status = '1'
                exception_info = str(e)
                logger.error(f'âŒ ç›´æ¥æ‰§è¡Œä»»åŠ¡ {job_info.job_name} å¤±è´¥: {e}')
            finally:
                # åŒæ­¥ä»»åŠ¡è®°å½•æ—¥å¿—ï¼ˆå¼‚æ­¥ä»»åŠ¡åœ¨ _execute_async_job_with_log ä¸­è®°å½•ï¼‰
                if not iscoroutinefunction(job_func):
                    cls._record_job_execution_log(job_info, job_executor, status, exception_info)
            return

        # åº”ç”¨é” workerï¼šé€šè¿‡ scheduler æ‰§è¡Œ
        job_trigger = DateTrigger()
        if job_info.status == '0':
            job_trigger = OrTrigger(triggers=[DateTrigger(), MyCronTrigger.from_crontab(job_info.cron_expression)])
        scheduler.add_job(
            func=job_func,
            trigger=job_trigger,
            args=job_info.job_args.split(',') if job_info.job_args else None,
            kwargs=json.loads(job_info.job_kwargs) if job_info.job_kwargs else None,
            id=str(job_info.job_id),
            name=job_info.job_name,
            misfire_grace_time=1000000000000 if job_info.misfire_policy == '3' else None,
            coalesce=job_info.misfire_policy == '2',
            max_instances=3 if job_info.concurrent == '0' else 1,
            jobstore=job_info.job_group,
            executor=job_executor,
        )

    @classmethod
    def remove_scheduler_job(cls, job_id: str | int) -> None:
        """
        æ ¹æ®ä»»åŠ¡idç§»é™¤ä»»åŠ¡

        :param job_id: ä»»åŠ¡id
        :return:
        """
        # éåº”ç”¨é” worker è·³è¿‡æ“ä½œï¼ˆæ•°æ®åº“çŠ¶æ€æ˜¯æŒä¹…åŒ–çš„ï¼ŒæŒæœ‰åº”ç”¨é”æ—¶ä¼šæ ¹æ®çŠ¶æ€åŠ è½½ï¼‰
        if not cls._is_leader:
            return
        query_job = cls.get_scheduler_job(job_id=job_id)
        if query_job:
            scheduler.remove_job(job_id=str(job_id))

    @classmethod
    def scheduler_event_listener(cls, event: SchedulerEvent) -> None:
        """
        è°ƒåº¦å™¨äº‹ä»¶ç›‘å¬å™¨ï¼Œè®°å½•ä»»åŠ¡æ‰§è¡Œæ—¥å¿—
        """
        try:
            # è·å–äº‹ä»¶ç±»å‹å’Œä»»åŠ¡ID
            event_type = event.__class__.__name__
            # è·å–ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸ä¿¡æ¯
            status = '0'
            exception_info = ''
            if event_type == 'JobExecutionEvent' and event.exception:
                exception_info = str(event.exception)
                status = '1'
            if hasattr(event, 'job_id'):
                job_id = event.job_id
                # è·³è¿‡å†…éƒ¨ç³»ç»Ÿä»»åŠ¡ï¼ˆä»¥ _ å¼€å¤´çš„ä»»åŠ¡IDï¼‰ï¼Œä¸è®°å½•æ—¥å¿—
                if str(job_id).startswith('_'):
                    return
                query_job = cls.get_scheduler_job(job_id=job_id)
                if query_job:
                    query_job_info = query_job.__getstate__()
                    # è·å–ä»»åŠ¡åç§°
                    job_name = query_job_info.get('name')
                    # è·å–ä»»åŠ¡ç»„å
                    job_group = query_job._jobstore_alias
                    # è·å–ä»»åŠ¡æ‰§è¡Œå™¨
                    job_executor = query_job_info.get('executor')
                    # è·å–è°ƒç”¨ç›®æ ‡å­—ç¬¦ä¸²
                    invoke_target = query_job_info.get('func')
                    # è·å–è°ƒç”¨å‡½æ•°ä½ç½®å‚æ•°ï¼ˆå®‰å…¨å¤„ç†ï¼‰
                    args = query_job_info.get('args')
                    job_args = ','.join(str(arg) for arg in args) if args else ''
                    # è·å–è°ƒç”¨å‡½æ•°å…³é”®å­—å‚æ•°
                    kwargs = query_job_info.get('kwargs')
                    job_kwargs = json.dumps(kwargs) if kwargs else '{}'
                    # è·å–ä»»åŠ¡è§¦å‘å™¨
                    job_trigger = str(query_job_info.get('trigger'))
                    # æ„é€ æ—¥å¿—æ¶ˆæ¯
                    job_message = f'äº‹ä»¶ç±»å‹: {event_type}, ä»»åŠ¡ID: {job_id}, ä»»åŠ¡åç§°: {job_name}, æ‰§è¡Œäº{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}'
                    job_log = JobLogModel(
                        jobName=job_name,
                        jobGroup=job_group,
                        jobExecutor=job_executor,
                        invokeTarget=invoke_target,
                        jobArgs=job_args,
                        jobKwargs=job_kwargs,
                        jobTrigger=job_trigger,
                        jobMessage=job_message,
                        status=status,
                        exceptionInfo=exception_info,
                        createTime=datetime.now(),
                    )
                    session = cls._get_session_local()()
                    try:
                        JobLogService.add_job_log_services(session, job_log)
                    finally:
                        session.close()
        except Exception as e:
            logger.error(f'âŒ è°ƒåº¦ä»»åŠ¡äº‹ä»¶ç›‘å¬å™¨å¼‚å¸¸: {e}')
